{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f8f8a4f-96a3-4f95-ba33-534f3065115e",
   "metadata": {
    "tags": []
   },
   "source": [
    "<center> <img src=\"https://pytorch.org/tutorials/_static/img/thumbnails/cropped/profiler.png\" width=\"150\" height=\"150\"/></center> <center> <h1><b><i>Introduction to Pytorch</i></b></h1></center>\n",
    "<center> <h3><i>Facebook's DeepLearning & Machine Learning Framework</i></h3></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7fd6bad-4ecc-49d3-8398-2c1f62394cd3",
   "metadata": {},
   "source": [
    "# *Introduction*\n",
    "\n",
    "<p style= \"font-size:120%\"><i><b>Tensor</b></i> - These are basically matrices to a very high rank.<br>Example of this would be an image [A 3-channel (red, green, blue) image which is 64 pixels wide and 64 pixels tall is a  3×64×64  tensor.]</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3395844a-74af-4909-9369-2acb52ef58fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1830960f-812c-49f8-99f5-68c200098c83",
   "metadata": {},
   "source": [
    "## *Tensor creation & properties*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "277eed36-7ce9-45c7-b623-e2dd88a00e06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 2.],\n",
       "         [3., 4.]],\n",
       "\n",
       "        [[5., 6.],\n",
       "         [7., 8.]],\n",
       "\n",
       "        [[9., 0.],\n",
       "         [1., 2.]]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create example tensor\n",
    "\n",
    "extensor = torch.Tensor(\n",
    "    [\n",
    "        [[1,2],[3,4]],\n",
    "        [[5,6],[7,8]], \n",
    "        [[9,0],[1,2]]\n",
    "    ]\n",
    ")\n",
    "\n",
    "extensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b947595b-4b22-4143-8f7e-0b47db891b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor device:  cpu\n",
      "Tensor shape:  torch.Size([3, 2, 2])\n",
      "Rank:  3\n",
      "Number of coefficients:  12\n"
     ]
    }
   ],
   "source": [
    "# Tensor properties\n",
    "\n",
    "print(\"Tensor device: \",extensor.device)\n",
    "print(\"Tensor shape: \",extensor.shape)\n",
    "print(\"Rank: \",len(extensor.shape))\n",
    "print(\"Number of coefficients: \",extensor.numel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd666060-bd3f-4b36-97a2-7489b90e0979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Element at (1,1) indices -  tensor([7., 8.])\n",
      "\n",
      "Element at the (1,1,1) index -  tensor(8.) \n",
      "Type -  <class 'torch.Tensor'>\n",
      "\n",
      "Element at the (1,1,1) index -  8.0 \n",
      "Type -  <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "# Accessing specific elements & their types\n",
    "\n",
    "print(\"Element at (1,1) indices - \",extensor[1][1])\n",
    "print(\"\\nElement at the (1,1,1) index - \", extensor[1][1][1], \"\\nType - \",type(extensor[1][1][1]))\n",
    "print(\"\\nElement at the (1,1,1) index - \", extensor[1][1][1].item(), \"\\nType - \",type(extensor[1][1][1].item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bf0850e-fafc-4b14-b82d-cca38dc83bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example tensor - \n",
      " tensor([[[1., 2.],\n",
      "         [3., 4.]],\n",
      "\n",
      "        [[5., 6.],\n",
      "         [7., 8.]],\n",
      "\n",
      "        [[9., 0.],\n",
      "         [1., 2.]]]) \n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([2., 6., 0.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get first element of each tensor in the current tensor\n",
    "# Here the (0,1) is the internal index from each sub matrix\n",
    "print(\"Example tensor - \\n\",extensor,\"\\n\\n\")\n",
    "extensor[:, 0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf95e109-0173-445d-b875-17a4e6e0e209",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "28e91280-6cb1-4716-a759-3cd1acde0247",
   "metadata": {},
   "source": [
    "## *Methods to create tensors in PyTorch*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "200bb07c-65f2-48ce-91cd-69032fab91fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Method 1 -\n",
      " tensor([[[1., 1.],\n",
      "         [1., 1.]],\n",
      "\n",
      "        [[1., 1.],\n",
      "         [1., 1.]],\n",
      "\n",
      "        [[1., 1.],\n",
      "         [1., 1.]]])\n",
      "\n",
      "\n",
      "Method 2 -\n",
      " tensor([[[0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 0.],\n",
      "         [0., 0.]]])\n",
      "\n",
      "\n",
      "Method 3 -\n",
      " tensor([[[-0.0400, -0.7003],\n",
      "         [-0.2335,  2.7244]],\n",
      "\n",
      "        [[ 0.1507, -2.1696],\n",
      "         [-0.9754, -1.3152]],\n",
      "\n",
      "        [[ 0.5193, -0.3705],\n",
      "         [-0.2675, -0.4955]]])\n",
      "\n",
      "\n",
      "Method 4 -\n",
      " tensor([[ 0.3844,  2.7677, -0.7787],\n",
      "        [ 0.0523, -0.6698, -1.7853],\n",
      "        [-1.1561, -0.2203, -1.5102]])\n"
     ]
    }
   ],
   "source": [
    "# Method 1 - Tensor with all 1s' of shape (extensor.shape)\n",
    "print(\"\\n\\nMethod 1 -\\n\",torch.ones_like(extensor))\n",
    "\n",
    "# Method 2 - Tensor with all 0s' of shape (extensor.shape)\n",
    "print(\"\\n\\nMethod 2 -\\n\",torch.zeros_like(extensor))\n",
    "\n",
    "# Method 3 - Tensor with all random numbers of shape (extensor.shape) - Random like extensor\n",
    "print(\"\\n\\nMethod 3 -\\n\",torch.randn_like(extensor))\n",
    "\n",
    "# Method 4 - Tensor from only shape and device\n",
    "print(\"\\n\\nMethod 4 -\\n\",torch.randn(3,3, device=\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8466d07-3ff7-4706-8c01-7e5b48a0e636",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82190b46-1612-4130-8d70-42d46c04df3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d1b350fe-f0e9-4d5d-8c24-34a73446b4a3",
   "metadata": {},
   "source": [
    "<center> <img src=\"https://pytorch.org/tutorials/_static/img/thumbnails/cropped/profiler.png\" width=\"150\" height=\"150\"/></center> <center> <h1><b><i>PyTorch - As a DeepLearning framework</i></b></h1></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f4d0a6a0-614f-4e0e-a87e-31537908fa19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn module from pytorch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c16e4f-8b71-4299-9a38-b6689a0ef028",
   "metadata": {},
   "source": [
    "### `nn.Linear`\n",
    "\n",
    "To create a linear layer, you need to pass it the number of input dimensions and the number of output dimensions. The linear object initialized as `nn.Linear(10, 2)` will take in a $n\\times10$ matrix and return an $n\\times2$ matrix, where all $n$ elements have had the same linear transformation performed. For example, you can initialize a linear layer which performs the operation $Ax + b$, where $A$ and $b$ are initialized randomly when you generate the [`nn.Linear()`](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html) object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba087f52-d1e5-4734-88ca-a2373c7a6215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  tensor([[ 0.5780,  0.9117, -1.9039, -0.4185, -1.2281,  1.2157, -2.7131, -0.1461,\n",
      "         -0.0768, -0.8076],\n",
      "        [-0.0731,  0.5010,  0.6021, -1.3893,  1.3945, -1.8512, -0.6994,  1.0924,\n",
      "          2.2604,  0.4381],\n",
      "        [-0.5080, -0.1629,  2.4953, -0.4880,  1.5919,  0.0756,  0.3597,  0.1017,\n",
      "         -0.3851, -1.5134]]) \n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2617,  0.0816],\n",
       "        [ 0.3904, -0.1394],\n",
       "        [ 0.0401, -0.5929]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear = nn.Linear(10,2)\n",
    "# Initialize a random tensor\n",
    "exinput = torch.randn(3,10)\n",
    "exout = linear(exinput)\n",
    "print(\"Input: \",exinput,\"\\n\\n\")\n",
    "exout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbe73a8-2059-48a2-b5c5-30a678218a37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dd0eb6bf-e303-44fa-b25d-43618bc15b42",
   "metadata": {},
   "source": [
    "### `nn.ReLU`\n",
    "\n",
    "[`nn.ReLU()`](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html) will create an object that, when receiving a tensor, will perform a ReLU activation function. This will be reviewed further in lecture, but in essence, a ReLU non-linearity sets all negative numbers in a tensor to zero. In general, the simplest neural networks are composed of series of linear transformations, each followed by activation functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5dd23416-0de2-4f54-abbb-757dcb1b7fa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0816],\n",
       "        [0.3904, 0.0000],\n",
       "        [0.0401, 0.0000]], grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relu = nn.ReLU()\n",
    "relu_out = relu(exout)\n",
    "relu_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71f525f-a377-4f33-8291-6c92bb59bbca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1caecb64-9692-4d89-bdfd-3baaf9b83cd7",
   "metadata": {},
   "source": [
    "### `nn.BatchNorm1D`\n",
    "\n",
    "[`nn.BatchNorm1d`](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html) is a normalization technique that will rescale a batch of $n$ inputs to have a consistent mean and standard deviation between batches.  \n",
    "\n",
    "As indicated by the `1d` in its name, this is for situations where you expect a set of inputs, where each of them is a flat list of numbers. In other words, each input is a vector, not a matrix or higher-dimensional tensor. For a set of images, each of which is a higher-dimensional tensor, you'd use [`nn.BatchNorm2d`](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html), discussed later on this page.\n",
    "\n",
    "`nn.BatchNorm1d` takes an argument of the number of input dimensions of each object in the batch (the size of each example vector)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f31c601c-646a-419c-beb5-958a2a70c587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features:  2\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of features: \",exout.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aac786bf-e39a-4bf8-8abf-35f1c98aff0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.8182,  1.4095],\n",
       "        [ 1.4078, -0.7047],\n",
       "        [-0.5896, -0.7047]], grad_fn=<NativeBatchNormBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Batch Normalization (num of features)\n",
    "batchnorm = nn.BatchNorm1d(2);\n",
    "batchnorm_out = batchnorm(relu_out)\n",
    "batchnorm_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1154d771-9c61-4d4d-b390-c67b40e35b80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "027b3cdb-8386-48a8-a200-e293d382ac2f",
   "metadata": {},
   "source": [
    "### `nn.Sequential`\n",
    "\n",
    "[`nn.Sequential`](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html) creates a single operation that performs a sequence of operations. For example, you can write a neural network layer with a batch normalization as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c8baee93-eafd-4018-b3db-11daff5c459a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: \n",
      " tensor([[ 1.0595,  1.0661,  1.4449, -0.1592,  1.2165],\n",
      "        [ 1.5318,  0.6325,  0.8639,  0.3034, -0.5190],\n",
      "        [ 2.6771,  0.4743,  1.2824, -0.3809,  1.7856],\n",
      "        [ 2.6985,  0.4521,  0.4706,  0.6911,  1.0830]])\n",
      "\n",
      "Layer Output: \n",
      " tensor([[0.0000, 0.0000],\n",
      "        [0.9691, 1.1057],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.9309, 0.8260]], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "layer = nn.Sequential(\n",
    "    # Same as Dense layer in TF\n",
    "    nn.Linear(in_features=5, out_features=2),\n",
    "    nn.BatchNorm1d(2),\n",
    "    nn.ReLU()\n",
    ")\n",
    "\n",
    "# Call layer\n",
    "data = torch.randn(4,5)+1\n",
    "print(\"Input: \\n\",data)\n",
    "print(\"\\nLayer Output: \\n\", layer(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf86105-1686-45c2-952d-7a1eea15ca1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8b38e896-c20d-4f22-8a86-dc774bf98b41",
   "metadata": {},
   "source": [
    "### `Optimizers`\n",
    "\n",
    "To create an optimizer in PyTorch, you'll need to use the `torch.optim` module, often imported as `optim`. [`optim.Adam`](https://pytorch.org/docs/stable/optim.html#torch.optim.Adam) corresponds to the Adam optimizer. To create an optimizer object, you'll need to pass it the parameters to be optimized and the learning rate, `lr`, as well as any other parameters specific to the optimizer.\n",
    "\n",
    "For all `nn` objects, you can access their parameters as a list using their `parameters()` method, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d728cb6b-4a7d-4bdb-971b-ae6add97f258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass the layer parameters to the optimizer\n",
    "\n",
    "adam_opt = optimizers.Adam(layer.parameters(), lr=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed9acdb-f8d2-403d-8d2e-7e8d43a397a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1a7f108a-4405-4d12-9e6f-ff89fa45dc74",
   "metadata": {},
   "source": [
    "### `Training in PyTorch`\n",
    "\n",
    "A (basic) training step in PyTorch consists of four basic parts:\n",
    "\n",
    "\n",
    "1.   Set all of the gradients to zero using `opt.zero_grad()`\n",
    "2.   Calculate the loss, `loss`\n",
    "3.   Calculate the gradients with respect to the loss using `loss.backward()`\n",
    "4.   Update the parameters being optimized using `opt.step()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1b2b3b4f-7ae6-4604-b6c9-3e0df39ddc77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.20308691263198853\n"
     ]
    }
   ],
   "source": [
    "data = torch.randn(100,5)+1\n",
    "\n",
    "# Step 1\n",
    "adam_opt.zero_grad()\n",
    "# Step 2\n",
    "loss = torch.abs(1-layer(data)).mean()\n",
    "# Step 3: Gradients for weights modification wrt the loss\n",
    "loss.backward()\n",
    "# Step 4: Update the parameters\n",
    "adam_opt.step()\n",
    "\n",
    "print(\"Loss: \",loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de8ffc8-f19d-40fa-b9d3-785b339ed2a4",
   "metadata": {},
   "source": [
    "#### `requires_grad_()`\n",
    "You can also tell PyTorch that it needs to calculate the gradient with respect to a tensor that you created by saying `example_tensor.requires_grad_()`, which will `change it in-place`. This means that even if PyTorch wouldn't normally store a grad for that particular tensor, it will for that specified tensor. <br><br>\n",
    "\n",
    "\n",
    "#### `with torch.no_grad():`\n",
    "PyTorch will usually calculate the gradients as it proceeds through a set of operations on tensors. This can often take up unnecessary computations and memory, especially if you're performing an evaluation. However, you can wrap a piece of code with `with torch.no_grad()` to prevent the gradients from being calculated in a piece of code. <br><br>\n",
    "\n",
    "\n",
    "#### `detach():`\n",
    "Sometimes, you want to calculate and use a tensor's value without calculating its gradients. For example, if you have two models, A and B, and you want to directly optimize the parameters of A with respect to the output of B, without calculating the gradients through B, then you could feed the detached output of B to A. There are many reasons you might want to do this, including efficiency or cyclical dependencies (i.e. A depends on B depends on A)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73a132e-d5a8-4f4a-bb3b-211bb01bda7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e486f692-a75b-48ea-9fce-1378368c7da8",
   "metadata": {},
   "source": [
    "# New `nn` Classes\n",
    "\n",
    "You can also create new classes which extend the `nn` module. For these classes, all class attributes, as in `self.layer` or `self.param` will automatically treated as parameters if they are themselves `nn` objects or if they are tensors wrapped in `nn.Parameter` which are initialized with the class. \n",
    "\n",
    "The `__init__` function defines what will happen when the object is created. The first line of the init function of a class, for example, `WellNamedClass`, needs to be `super(WellNamedClass, self).__init__()`. \n",
    "\n",
    "The `forward` function defines what runs if you create that object `model` and pass it a tensor `x`, as in `model(x)`. If you choose the function signature, `(self, x)`, then each call of the forward function, gets two pieces of information: `self`, which is a reference to the object with which you can access all of its parameters, and `x`, which is the current tensor for which you'd like to return `y`.\n",
    "\n",
    "One class might look like the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6aa12dda-759f-4281-a103-6d1b909d272c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExampleModule(nn.Module):\n",
    "#     Constructor in Python\n",
    "    def __init__(self,input_dims,output_dims):\n",
    "        super(ExampleModule,self).__init__()\n",
    "        # Here self.data_member_name\n",
    "        self.linear = nn.Linear(input_dims,output_dims)\n",
    "        self.exponent = nn.Parameter(torch.tensor(1.))\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.linear(x)\n",
    "        x = x**self.exponent\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a85b3b9d-f826-48ee-8921-a7749949084e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6112, -0.3306],\n",
       "        [ 0.3569,  0.6215],\n",
       "        [-0.1654, -0.6504],\n",
       "        [ 1.0556,  0.7813]], grad_fn=<PowBackward1>)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calling the Module\n",
    "# Create new object\n",
    "model = ExampleModule(10,2)\n",
    "\n",
    "# Create new data\n",
    "input = torch.randn(4,10)\n",
    "model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f131c0-9447-4e9b-a2a6-f6a65506be31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "83c4f7f7-8ca4-418e-bf62-c173be4dccd5",
   "metadata": {},
   "source": [
    "## `2D Operations`\n",
    "\n",
    "You won't need these for the first lesson, and the theory behind each of these will be reviewed more in later lectures, but here is a quick reference: \n",
    "\n",
    "\n",
    "*   2D convolutions: [`nn.Conv2d`](https://pytorch.org/docs/master/generated/torch.nn.Conv2d.html) requires the number of input and output channels, as well as the kernel size.\n",
    "*   2D transposed convolutions (aka deconvolutions): [`nn.ConvTranspose2d`](https://pytorch.org/docs/master/generated/torch.nn.ConvTranspose2d.html) also requires the number of input and output channels, as well as the kernel size\n",
    "*   2D batch normalization: [`nn.BatchNorm2d`](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html) requires the number of input dimensions\n",
    "*   Resizing images: [`nn.Upsample`](https://pytorch.org/docs/master/generated/torch.nn.Upsample.html) requires the final size or a scale factor. Alternatively, [`nn.functional.interpolate`](https://pytorch.org/docs/stable/nn.functional.html#torch.nn.functional.interpolate) takes the same arguments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2603fe-3a2b-474a-8ee0-3d00fc67e0eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
